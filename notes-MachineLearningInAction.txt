notes-MachineLearningInAction      by xuchangtiao

机器学习的真实含义：
    机器学习能让我们自数据集中受到启发，我们利用计算机来彰显数据背后的真实含义。
    机器学习就是把无序的数据转换成有用的信息。
机器学习的主要任务：
    1.监督学习：
        1）分类。将实例数据划分到合适的分类中。
        2）回归。主要用于预测数值型数据。
    2.无监督学习：
        1）聚类。
        2）密度估计。
训练集：用于训练机器学习算法的数据样本集合。
标称型（离散的）、数值型（连续的）。
开发机器学习应用程序的步骤：
    1.收集数据。利用各种方法收集样本数据。
    2.准备输入数据。确保数据格式符合要求，本书使用Python的List。
    3.分析输入数据。主要确保数据集中没有垃圾数据。
    4.训练算法。无监督学习跳过这一步。
    5.测试算法。不满意则跳回第4步甚至第1步继续。
    6.使用算法。
Python：
    1.优点：
        1）语法清晰，被称为可执行伪代码。
        2）易于操作纯文本文件，易于处理非数值型数据。
        3）使用广泛，存在大量的开发文档。
    2.缺点：
        1）性能问题。

第2章 K-近邻算法
k-近邻算法（kNN）：
    1）简单地说，k-近邻算法采用测量不同特征值之间的距离方法进行分类。
    2）优点：精度高、对异常值不敏感、无数据输入假设。
    3）缺点：计算复杂度高、空间复杂度高。
    4）适用数据范围：数值型和标称型。
    5）工作原理：存在一个样本数据集合，也称为样本训练集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据与所属分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的k（通常k不大于20）个分类标签。选择这k个里出现次数最多的分类，作为新数据的分类。

第3章 决策树
决策树：
    1.主要优势：决策树的主要优势就在于数据形式非常容易理解。
    2.优点：计算复杂度不高，输出结果易于理解，对中间值缺失不敏感，可以处理不相关特征数据，还可以持久化地将分类器保存在硬盘上。
    3.缺点：可能会产生过度匹配问题。
    4.适用数据类型：数值型和标称型。
    5.ID3算法可以用于划分标称型数据集。
    6.利用递归的方法将数据集转化为决策树。
    7.使用Python语言内嵌的数据结构字典存储树节点信息。
信息增益：
    1.划分数据集的大原则是：将无序的数据变得更加有序。
    2.获得信息增益最高的特征就是最好的选择。
Python中的pickle序列化对象：
    序列化对象可以在磁盘上保存对象，并在需要的时候读取出来。任何对象都可以执行序列化操作。

第4章 朴素贝叶斯
朴素贝叶斯
    1）优点：在数据较少的情况下仍然有效，可以处理多类别问题。
    2）缺点：对于输入数据的准备方式较为敏感。
    3）使用数据类型：标称型数据。
贝叶斯决策理论的核心思想：选择具有最高概率的决策。
贝叶斯准则：告诉我们如何交换条件概率中的条件与结果。
    如果已知P(x|c)，要求P(c|x)：
        P(c|x) = (P(x|c) * P(c)) / P(x
朴素贝叶斯是贝叶斯分类器的一个扩展，是用于文档分类的常用算法。
朴素贝叶斯的假设：
    1）每个特征之间相互独立。
    2）每个特征同等重要。
为降低概率值为0导致最后乘积也为0的影响，可以将所有次的出现数初始化为1，并将分母初始化为2；
为处理下溢出的问题，可以采用自然对数进行处理，不会有任何损失，且不影响最终结果。
词集模型：在文档中出现的词只记录一次。
词袋模型：在文档中出现的词记录出现的次数。
留存交叉验证：随机选择数据的一部分作为训练集，而剩余部分作为测试集的过程。

第5章 Logistic回归